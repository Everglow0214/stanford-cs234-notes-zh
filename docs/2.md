# Lecture 2 Making Good Decisions Given a Model of the World

# 课时2 已知环境模型时，如何做出好的决策 2019.01.09

## 3. 在马尔可夫决策过程中做出动作（Acting in a Markov decision process）

我们从回忆模型（model）、策略（policy）和值函数（value function）的定义开始。令行为体的状态空间和动作空间分别表示为 $S$ 和 $A$，那么，

$\bullet$ 模型：模型是行为体所处的环境的状态转移与奖励的数学模型，包括状态转移概率 P(s'|s,a)，表示状态 $s\in S$ 在执行动作 $a\in A$ 后，状态转移到 $s'\in S$ 后的概率，以及在状态 $s\in S$ 执行动作 $a\in A$ 后得到的奖励 $R(s,a)$（确定的或随机的）。

$\bullet$ 策略：策略是一个将行为体的状态映射到动作的函数 $\pi:S\rightarrow A$。

$\bullet$ 值函数：对应于特定策略 $\pi$ 和状态 $s\in S$ 的值函数 $V^{\pi}$ 是行为体从状态 $s$ 开始，遵循策略 $\pi$ 所能获得的未来（衰减）奖励的累加。

同时回忆一下上节课提到的马尔可夫性质（Markov property）的概念。考虑一个遵循某个转移规律的随机过程 $(s_0,s_1,s_2,...)$，我们称这个随机过程有马尔可夫性质当且仅当对于 $\forall i=1,2,...$，$P(s_i|s_0,...,s_{i-1})=P(s_i|s_{i-1})$，即以包括当前状态在内的历史为条件的转移到下一状态的概率，与仅以当前状态为条件的转移到下一状态的概率相等。在这种情况下，当前状态是随机过程的历史的一个充分统计，我们认为“未来与过去无关”。